{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_csv(data_name):\n",
    "    if \"tsv\" in data_name:\n",
    "        data = pd.read_csv(data_name,\n",
    "                            sep='\\t',\n",
    "                            encoding = \"utf-8\",\n",
    "                            engine = \"python\",\n",
    "                            header = 0)\n",
    "    elif \"csv\" in data_name:\n",
    "        data = pd.read_csv(data_name,\n",
    "                        encoding = \"utf-8\",\n",
    "                        engine = \"python\",\n",
    "                        header = 0)\n",
    "    else:\n",
    "        raise NotImplementedError(\"Given data file type is not supported yet.\")\n",
    "    return data\n",
    "\n",
    "def print_data_info(data, split, label_col):\n",
    "    label_counts = data[label_col].value_counts().to_dict()\n",
    "    output = f\"{split}\\t{len(data)}\"\n",
    "    for label in sorted(label_counts.keys()):\n",
    "        output += f\"\\t{label}: {label_counts[label]}, \"\n",
    "        output += \"{:.1%}\".format(label_counts[label]/len(data))\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# US Election 2020: binary - HOF, Non-HOF\n",
    "train_data = read_from_csv(\"data/us-election-2020/train.tsv\")\n",
    "train_data[\"label\"] = 0\n",
    "train_data[\"label\"] = train_data[\"label\"].where(train_data[\"HOF\"] == \"Non-Hateful\", 1)\n",
    "train_data.to_csv(\"./data/us-election-2020/train_clean.csv\", index=False)\n",
    "\n",
    "test_data = read_from_csv(\"data/us-election-2020/test.tsv\")\n",
    "test_data[\"label\"] = 0\n",
    "test_data[\"label\"] = test_data[\"label\"].where(test_data[\"HOF\"] == \"Non-Hateful\", 1)\n",
    "test_data.to_csv(\"./data/us-election-2020/test_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Davidson-THON: multi - 0: hate speech, 1: offensive language, 2: neither\n",
    "data = read_from_csv(\"data/davidson-thon/davidson-thon.csv\")\n",
    "data = data.rename(columns={\"tweet\": \"text\"})\n",
    "data = data.rename(columns={\"class\": \"label_multi\"})\n",
    "data = data[[\"text\", \"label_multi\"]]\n",
    "data.to_csv(\"./data/davidson-thon/data_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "        0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "y = [torch.tensor(1), torch.tensor(1), torch.tensor(0), torch.tensor(0), torch.tensor(1), torch.tensor(1), torch.tensor(0), torch.tensor(1), torch.tensor(1), torch.tensor(0), torch.tensor(0), torch.tensor(1), torch.tensor(1), torch.tensor(1), torch.tensor(1), torch.tensor(1), torch.tensor(0), torch.tensor(0), torch.tensor(1), torch.tensor(1), torch.tensor(0), torch.tensor(0), torch.tensor(1), torch.tensor(0), torch.tensor(0), torch.tensor(1), torch.tensor(0), torch.tensor(0), torch.tensor(0), torch.tensor(1), torch.tensor(1), torch.tensor(0), torch.tensor(1), torch.tensor(0), torch.tensor(1), torch.tensor(1), torch.tensor(0), torch.tensor(1), torch.tensor(0), torch.tensor(0), torch.tensor(1), torch.tensor(1), torch.tensor(1), torch.tensor(1), torch.tensor(0), torch.tensor(0), torch.tensor(1), torch.tensor(1), torch.tensor(1), torch.tensor(1), torch.tensor(1), torch.tensor(0), torch.tensor(0), torch.tensor(1), torch.tensor(0), torch.tensor(0), torch.tensor(1), torch.tensor(1), torch.tensor(0), torch.tensor(0), torch.tensor(1), torch.tensor(1), torch.tensor(0), torch.tensor(1), torch.tensor(0), torch.tensor(0), torch.tensor(1), torch.tensor(1), torch.tensor(0), torch.tensor(1), torch.tensor(1), torch.tensor(0), torch.tensor(0), torch.tensor(0), torch.tensor(0), torch.tensor(0), torch.tensor(0), torch.tensor(0), torch.tensor(0), torch.tensor(0)]\n",
    "torch.stack(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    1686\n",
       "1     234\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if all samples appear in the resampled training set\n",
    "train = read_from_csv(\"resampled_train_data.csv\")\n",
    "train.groupby(\"label\").text.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    15380\n",
       "1    15340\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.6250), tensor(0.6667), tensor([0.7500, 0.5000]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import tensor\n",
    "from torchmetrics.classification import Precision, Recall, F1Score\n",
    "target = tensor([0, 0, 0, 0, 1, 0])\n",
    "preds = tensor([1, 0, 0, 1, 1, 0])\n",
    "f1_macro = F1Score(task=\"multiclass\", num_classes=2, average=\"macro\")\n",
    "f1_micro = F1Score(task=\"multiclass\", num_classes=2, average=\"micro\")\n",
    "f1_per_label = F1Score(task=\"multiclass\", num_classes=2, average=\"none\")\n",
    "f1_macro(preds, target), f1_micro(preds, target), f1_per_label(preds, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.625, 0.6666666666666666)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(preds, target, average='macro'), f1_score(preds, target, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import tensor\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = tensor([0, 2, 1, 2])\n",
    "y_true = tensor([0, 1, 2, 2])\n",
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5000)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchmetrics.classification import Precision, Recall, F1Score, Accuracy, AveragePrecision\n",
    "accuracy = Accuracy(task=\"multiclass\", num_classes=4, average=\"weighted\")\n",
    "accuracy(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ailab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
