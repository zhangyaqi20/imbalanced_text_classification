{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_names = ['bretschneider-th-main', 'bretschneider-th-school', 'cmsb-tsd', 'gao-2018-fhc', 'gibert-2018-shs', 'twitter-hate-speech-tsa', 'us-election-2020', 'waseem-and-hovy-2016']\n",
    "multi_class_data_names = ['ami', 'davidson-thon', 'founta-2018-thas']\n",
    "data_cols = ['data_name', 'num_classes', 'data_type', 'label_col',]\n",
    "variant_cols = ['variant', 'sampling_modifiedRS_rho', 'sampling_weightedRS_percentage', 'loss', 'wce_alpha', 'fl_gamma',]\n",
    "metrics_cols = ['val_f1_macro',\n",
    "                'test_f1_macro', \n",
    "                'test_f1_per_label_0', \n",
    "                'test_f1_per_label_1',\n",
    "                'test_f1_per_label_2', \n",
    "                'test_f1_per_label_3',\n",
    "                'test_f1_per_label_4',\n",
    "                'test_accuracy', \n",
    "                'test_precision_macro',\n",
    "                'test_precision_weighted',\n",
    "                'test_recall_macro',\n",
    "                'test_recall_weighted',\n",
    "                'test_auprc',]\n",
    "COLS = data_cols + variant_cols + ['pl_seed'] + metrics_cols + ['mlflow_run_id']\n",
    "\n",
    "results_excel_path = \"results_all.xlsx\"\n",
    "cols_results = ['data_name', 'num_classes', \n",
    "                'variant', 'sampling_modifiedRS_rho', 'sampling_weightedRS_percentage', 'wce_alpha', 'fl_gamma',\n",
    "                'val_f1_macro', 'test_f1_macro', 'test_f1_macro_std'] + metrics_cols[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value_by_run_id(data_dir, run_id, key):\n",
    "    value = None\n",
    "    for root, _, files in os.walk(data_dir + run_id):  \n",
    "        if key in files:\n",
    "            with open(f\"{root}/{key}\", \"r\") as f:\n",
    "                value = f.readlines()[-1]\n",
    "                if \"val\" in key or \"test\" in key:\n",
    "                    value = value.split()[1]\n",
    "                if value == \"sampling_modifiedRS\": # Forgot to specify in the variant value\n",
    "                    value += \"_oversampling\"\n",
    "                try:\n",
    "                    value = ast.literal_eval(value)\n",
    "                    if isinstance(value, list):\n",
    "                        value = [round(v, 2) for v in value]\n",
    "                        value = tuple(value)\n",
    "                except (ValueError, SyntaxError):\n",
    "                    pass\n",
    "                break\n",
    "    if value is None:\n",
    "        value = \"-\"\n",
    "        if \"test\" in key:\n",
    "            value = 0\n",
    "    return value\n",
    "\n",
    "def get_log_by_data_name(data_name):\n",
    "    data_runs_dir = f'../logs/{data_name}/'\n",
    "    run_ids = os.listdir(data_runs_dir)\n",
    "    rows = []\n",
    "    for run_id in run_ids:\n",
    "        run_result = {col_name: get_value_by_run_id(data_runs_dir, run_id, col_name) for col_name in COLS[:-1]}\n",
    "        run_result['mlflow_run_id'] = run_id\n",
    "        rows.append(run_result)\n",
    "    df = pd.DataFrame(columns=COLS, data=rows)\n",
    "    df.to_csv(f\"results_{data_name}_raw.csv\", index=False)\n",
    "    return df\n",
    "\n",
    "def aggregate_results(data_name, writer):\n",
    "    # Get raw mlflow logs:\n",
    "    df = get_log_by_data_name(data_name)\n",
    "    df.to_excel(writer, sheet_name=f\"{data_name}_raw\")\n",
    "    assert len(df) % 3 == 0\n",
    "    # assert len(df[df[\"test_f1_macro\"] == 0]) == 0\n",
    "    # Aggregate results from 3 seeds\n",
    "    agg_target = {metric: 'mean' for metric in metrics_cols}\n",
    "    agg_target.update({col: 'first' for col in data_cols})\n",
    "    df['test_f1_macro_std'] = df.loc[:, 'test_f1_macro']\n",
    "    agg_target.update({'test_f1_macro_std': 'std'})\n",
    "    df_seeds_mean = df.groupby(variant_cols, as_index=False).agg(agg_target)\n",
    "    #  - add wfl(alpha=1.0) => fl\n",
    "    df_seeds_mean.loc[(df_seeds_mean[\"variant\"] == \"wfl\") & (df_seeds_mean[\"wce_alpha\"] == 1.0),  \"variant\"] = \"fl\"\n",
    "    #  - change metric to be 00.00\n",
    "    for metric in metrics_cols + ['test_f1_macro_std']:\n",
    "        df_seeds_mean[metric] = df_seeds_mean[metric].apply(lambda x: \"{0:.2f}\".format(x*100))\n",
    "    #  - re-order the columns\n",
    "    df_seeds_mean = df_seeds_mean[cols_results]\n",
    "    df_seeds_mean.to_excel(writer, sheet_name=f\"{data_name}_seeds-mean\")\n",
    "    df_val_f1_max = df_seeds_mean.loc[df_seeds_mean.groupby([\"variant\"])['val_f1_macro'].idxmax()].reset_index(drop=True)\n",
    "    return df_val_f1_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mounts/Users/cisintern/zhangyaq/anaconda3/envs/pl_env/lib/python3.12/site-packages/openpyxl/workbook/child.py:99: UserWarning: Title is more than 31 characters. Some applications may not be able to read the file\n",
      "  warnings.warn(\"Title is more than 31 characters. Some applications may not be able to read the file\")\n",
      "/mounts/Users/cisintern/zhangyaq/anaconda3/envs/pl_env/lib/python3.12/site-packages/openpyxl/workbook/child.py:99: UserWarning: Title is more than 31 characters. Some applications may not be able to read the file\n",
      "  warnings.warn(\"Title is more than 31 characters. Some applications may not be able to read the file\")\n",
      "/mounts/Users/cisintern/zhangyaq/anaconda3/envs/pl_env/lib/python3.12/site-packages/openpyxl/workbook/child.py:99: UserWarning: Title is more than 31 characters. Some applications may not be able to read the file\n",
      "  warnings.warn(\"Title is more than 31 characters. Some applications may not be able to read the file\")\n"
     ]
    }
   ],
   "source": [
    "writer = pd.ExcelWriter(results_excel_path)\n",
    "df_all_agg_results = pd.DataFrame(columns=cols_results)\n",
    "for data_name in data_names + multi_class_data_names:\n",
    "    df_val_f1_max = aggregate_results(data_name, writer)\n",
    "    df_all_agg_results = pd.concat([df_all_agg_results, df_val_f1_max], ignore_index=True)\n",
    "df_all_agg_results = df_all_agg_results.sort_values(by=['data_name']).reset_index(drop=True)\n",
    "df_all_agg_results.to_excel(writer, sheet_name=f\"best_of_all\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_name</th>\n",
       "      <th>variant</th>\n",
       "      <th>test_f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bretschneider-th-main</td>\n",
       "      <td>baseline</td>\n",
       "      <td>68.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bretschneider-th-main</td>\n",
       "      <td>sampling_modifiedRS_oversampling</td>\n",
       "      <td>73.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bretschneider-th-main</td>\n",
       "      <td>sampling_weightedRS</td>\n",
       "      <td>70.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bretschneider-th-main</td>\n",
       "      <td>th</td>\n",
       "      <td>70.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bretschneider-th-main</td>\n",
       "      <td>wce</td>\n",
       "      <td>70.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bretschneider-th-school</td>\n",
       "      <td>wce</td>\n",
       "      <td>74.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bretschneider-th-school</td>\n",
       "      <td>sampling_weightedRS</td>\n",
       "      <td>73.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bretschneider-th-school</td>\n",
       "      <td>th</td>\n",
       "      <td>74.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bretschneider-th-school</td>\n",
       "      <td>baseline</td>\n",
       "      <td>69.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bretschneider-th-school</td>\n",
       "      <td>sampling_modifiedRS_oversampling</td>\n",
       "      <td>76.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cmsb-tsd</td>\n",
       "      <td>baseline</td>\n",
       "      <td>84.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cmsb-tsd</td>\n",
       "      <td>th</td>\n",
       "      <td>84.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>davidson-thon</td>\n",
       "      <td>sampling_modifiedRS_oversampling</td>\n",
       "      <td>75.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>davidson-thon</td>\n",
       "      <td>wce</td>\n",
       "      <td>75.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>davidson-thon</td>\n",
       "      <td>th</td>\n",
       "      <td>74.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>davidson-thon</td>\n",
       "      <td>sampling_weightedRS</td>\n",
       "      <td>74.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>davidson-thon</td>\n",
       "      <td>baseline</td>\n",
       "      <td>74.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>founta-2018-thas</td>\n",
       "      <td>baseline</td>\n",
       "      <td>62.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>founta-2018-thas</td>\n",
       "      <td>th</td>\n",
       "      <td>61.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>founta-2018-thas</td>\n",
       "      <td>sampling_modifiedRS_oversampling</td>\n",
       "      <td>62.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gibert-2018-shs</td>\n",
       "      <td>baseline</td>\n",
       "      <td>76.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>twitter-hate-speech-tsa</td>\n",
       "      <td>baseline</td>\n",
       "      <td>87.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>us-election-2020</td>\n",
       "      <td>wce</td>\n",
       "      <td>77.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>us-election-2020</td>\n",
       "      <td>wfl</td>\n",
       "      <td>74.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>us-election-2020</td>\n",
       "      <td>sampling_weightedRS</td>\n",
       "      <td>76.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>us-election-2020</td>\n",
       "      <td>fl</td>\n",
       "      <td>74.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>us-election-2020</td>\n",
       "      <td>baseline</td>\n",
       "      <td>75.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>us-election-2020</td>\n",
       "      <td>th</td>\n",
       "      <td>77.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>us-election-2020</td>\n",
       "      <td>sampling_modifiedRS_oversampling</td>\n",
       "      <td>73.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>waseem-and-hovy-2016</td>\n",
       "      <td>baseline</td>\n",
       "      <td>86.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>waseem-and-hovy-2016</td>\n",
       "      <td>sampling_weightedRS</td>\n",
       "      <td>87.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>waseem-and-hovy-2016</td>\n",
       "      <td>wce</td>\n",
       "      <td>86.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>waseem-and-hovy-2016</td>\n",
       "      <td>wfl</td>\n",
       "      <td>86.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  data_name                           variant test_f1_macro\n",
       "0     bretschneider-th-main                          baseline         68.89\n",
       "1     bretschneider-th-main  sampling_modifiedRS_oversampling         73.72\n",
       "2     bretschneider-th-main               sampling_weightedRS         70.68\n",
       "3     bretschneider-th-main                                th         70.60\n",
       "4     bretschneider-th-main                               wce         70.82\n",
       "5   bretschneider-th-school                               wce         74.49\n",
       "6   bretschneider-th-school               sampling_weightedRS         73.99\n",
       "7   bretschneider-th-school                                th         74.11\n",
       "8   bretschneider-th-school                          baseline         69.82\n",
       "9   bretschneider-th-school  sampling_modifiedRS_oversampling         76.23\n",
       "10                 cmsb-tsd                          baseline         84.36\n",
       "11                 cmsb-tsd                                th         84.91\n",
       "12            davidson-thon  sampling_modifiedRS_oversampling         75.48\n",
       "13            davidson-thon                               wce         75.67\n",
       "14            davidson-thon                                th         74.33\n",
       "15            davidson-thon               sampling_weightedRS         74.66\n",
       "16            davidson-thon                          baseline         74.70\n",
       "17         founta-2018-thas                          baseline         62.70\n",
       "18         founta-2018-thas                                th         61.90\n",
       "19         founta-2018-thas  sampling_modifiedRS_oversampling         62.74\n",
       "20          gibert-2018-shs                          baseline         76.89\n",
       "21  twitter-hate-speech-tsa                          baseline         87.21\n",
       "22         us-election-2020                               wce         77.02\n",
       "23         us-election-2020                               wfl         74.73\n",
       "24         us-election-2020               sampling_weightedRS         76.51\n",
       "25         us-election-2020                                fl         74.44\n",
       "26         us-election-2020                          baseline         75.62\n",
       "27         us-election-2020                                th         77.06\n",
       "28         us-election-2020  sampling_modifiedRS_oversampling         73.49\n",
       "29     waseem-and-hovy-2016                          baseline         86.72\n",
       "30     waseem-and-hovy-2016               sampling_weightedRS         87.46\n",
       "31     waseem-and-hovy-2016                               wce         86.68\n",
       "32     waseem-and-hovy-2016                               wfl         86.35"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_agg_results[[\"data_name\", \"variant\", \"test_f1_macro\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['591e1b6a525c4c1dba299078504b6c90', '2a8795a8ef444002bba32c9593ddeafd', '6ae407f7e7554429b704e521e2efb632', 'b4067e94e0b24f5dbaa2337056dc7578', '442c82a0d1d845098b81eba8565ba978']\n"
     ]
    }
   ],
   "source": [
    "mlrun_ids = []\n",
    "\n",
    "with open(\"../outputs/bretschneider-th-school_sampling_weightedRS_seed0_output.txt\", \"r\") as f:\n",
    "    log_contents = f.readlines()\n",
    "    mlrun_ids += [log.split(\"/\")[-1][:-2] for log in log_contents if \"MLflow Saved Child Search\" in log]\n",
    "\n",
    "print(mlrun_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3fa9dacc654d4dd993daa99f3154797d\tus-election-2020-wfl-Trial_32-wce_alpha=0.5-fl_gamma=0.2-seed0-epoch=04-val_f1_macro=0.81.ckpt\n",
      "059235d3daee43e8abb12b633429386e\tus-election-2020-wfl-Trial_22-wce_alpha=0.5-fl_gamma=2.0-seed42-epoch=09-val_f1_macro=0.79.ckpt\n",
      "812856c9519d41a294ca58b95df133a0\tus-election-2020-wfl-Trial_1-wce_alpha=0.5-fl_gamma=1.0-seed42-epoch=05-val_f1_macro=0.81.ckpt\n",
      "d0011460968d440ea1f49694f9c2054a\tus-election-2020-wfl-Trial_17-wce_alpha=0.5-fl_gamma=0.1-seed42-epoch=03-val_f1_macro=0.79.ckpt\n",
      "37dfc6631af44732a68131dbe49eaa3c\tus-election-2020-wfl-Trial_21-wce_alpha=0.5-fl_gamma=0.2-seed21-epoch=08-val_f1_macro=0.79.ckpt\n",
      "3e4fbd90dc3f4d95ba4bac5e6ed52864\tus-election-2020-wfl-Trial_35-wce_alpha=0.5-fl_gamma=2.0-seed0-epoch=06-val_f1_macro=0.78.ckpt\n",
      "9ec9ef85e7414db9bfeb9d1157e0b502\tus-election-2020-wfl-Trial_26-wce_alpha=0.5-fl_gamma=0.2-seed42-epoch=03-val_f1_macro=0.81.ckpt\n",
      "ba14e53c72b748b78f2386dee1bc74a1\tus-election-2020-wfl-Trial_8-wce_alpha=0.5-fl_gamma=2.0-seed21-epoch=08-val_f1_macro=0.81.ckpt\n",
      "a33b128a021341caacfbc84d5e607128\tus-election-2020-wfl-Trial_26-wce_alpha=0.5-fl_gamma=0.1-seed21-epoch=07-val_f1_macro=0.81.ckpt\n",
      "034289e188104fd980fbef0a5c639173\tus-election-2020-wfl-Trial_32-wce_alpha=0.5-fl_gamma=0.5-seed42-epoch=03-val_f1_macro=0.79.ckpt\n",
      "8a59ae613765457197ef45d20785d929\tus-election-2020-wfl-Trial_34-wce_alpha=0.5-fl_gamma=5.0-seed0-epoch=09-val_f1_macro=0.78.ckpt\n",
      "e306d5920d514804ba68cd23f543f1a0\tus-election-2020-wfl-Trial_13-wce_alpha=0.5-fl_gamma=0.5-seed0-epoch=06-val_f1_macro=0.83.ckpt\n",
      "83a1c977f9174f17aaf296fcd2316bce\tus-election-2020-wfl-Trial_12-wce_alpha=0.5-fl_gamma=0.1-seed0-epoch=05-val_f1_macro=0.83.ckpt\n",
      "4cec9a68a11f4045bfec0482ff0b1f78\tus-election-2020-wfl-Trial_5-wce_alpha=0.5-fl_gamma=0.5-seed21-epoch=06-val_f1_macro=0.81.ckpt\n",
      "e161490ae72442ed9743f987480bf073\tus-election-2020-wfl-Trial_27-wce_alpha=0.5-fl_gamma=5.0-seed42-epoch=03-val_f1_macro=0.80.ckpt\n",
      "8db86a22f4704ca5b786fed9eeb36f99\tus-election-2020-wfl-Trial_32-wce_alpha=0.5-fl_gamma=1.0-seed21-epoch=02-val_f1_macro=0.79.ckpt\n",
      "e5c2125a7a8443d4a1b4454f7d9b1ee1\tus-election-2020-wfl-Trial_28-wce_alpha=0.5-fl_gamma=5.0-seed21-epoch=02-val_f1_macro=0.77.ckpt\n",
      "b1b0a7b2f3c5418a92239d3f911443d4\tus-election-2020-wfl-Trial_23-wce_alpha=0.5-fl_gamma=1.0-seed0-epoch=06-val_f1_macro=0.81.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_runs_dir = f'../logs/us-election-2020/'\n",
    "run_ids = os.listdir(data_runs_dir)\n",
    "logs = dict()\n",
    "for run_id in run_ids:\n",
    "    ckpt_dir = f\"{data_runs_dir}{run_id}/artifacts/model_checkpoints/\"\n",
    "    try:\n",
    "        ckpt = os.listdir(ckpt_dir)[0]\n",
    "        if \"wce_alpha=0.5\" in ckpt:    \n",
    "            logs[run_id] = ckpt\n",
    "            print(f\"{run_id}\\t{ckpt}\")\n",
    "    except NotADirectoryError:\n",
    "        pass\n",
    "len(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
